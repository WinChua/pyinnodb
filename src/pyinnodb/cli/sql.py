import json
import dataclasses

from pyinnodb.disk_struct.index import MIndexPage, MSDIPage
from pyinnodb.sdi.table import Table

from . import *

logger = logging.getLogger(__name__)


@main.command()
@click.pass_context
@click.option(
    "--mode", type=click.Choice(["sdi", "ddl", "dump", "json"]), default="ddl"
)
@click.option("--sdi-idx", type=click.INT, default=0)
@click.option("--sdi-name", type=click.STRING, default=None)
@click.option("--schema/--no-schema", default=True)
@click.option("--sdi-page-no", type=click.INT, default=None)
def tosql(ctx, mode, sdi_idx, sdi_name, schema, sdi_page_no):
    """dump the ddl/dml/sdi of the ibd table

    ddl) output the create table ddl;
    dump) output the dml of ibd file;
    sdi) output the dd_object stored in the SDIPage as json format
    json) dump records in json format
    """

    f = ctx.obj["fn"]
    fsp_page = ctx.obj["fsp_page"]
    logger.debug("fsp header is %s", fsp_page.fsp_header)
    logger.debug("fsp page is %s", fsp_page.fil)
    page_no = fsp_page.get_sdi_page_no_with_guess(f)
    logger.debug("fsp sdi guess is %d", fsp_page.get_sdi_page_no_with_guess(f))
    if page_no is not None or sdi_page_no is not None:
        if page_no is None:
            page_no = sdi_page_no
        f.seek(page_no * const.PAGE_SIZE)
        sdi_page = MSDIPage.parse_stream(f)
        dd_obj = sdi_page.ddl(f, sdi_idx)["dd_object"]
        table_object = Table(**dd_obj)

        if mode == "sdi":
            print(json.dumps(dd_obj))
        elif mode == "ddl":
            print(table_object.gen_ddl(schema))
        elif mode == "json":
            dump_ibd(table_object, f, in_json=True)
        else:
            dump_ibd(table_object, f)
        return
    else:
        print(
            "the file may not generated by mysql 8, if you're sure that, you can specify --sdi-page-no 3"
        )


def dump_ibd(table_object, f, oneline=True, in_json=False):
    root_page_no = int(table_object.indexes[0].private_data.get("root", 4))
    f.seek(root_page_no * const.PAGE_SIZE)
    root_index_page = MIndexPage.parse_stream(f)
    first_leaf_page_no = root_index_page.get_first_leaf_page(
        f, table_object.get_primary_key_col()
    )
    if first_leaf_page_no is None:
        print("no data")
        return

    transfer = table_object.wrap_transfer
    if in_json:
        transfer = None
    default_value_parser = MIndexPage.default_value_parser(table_object, transfer)

    values = []
    while first_leaf_page_no != const.FFFFFFFF:
        f.seek(first_leaf_page_no * const.PAGE_SIZE)
        index_page = MIndexPage.parse_stream(f)
        values.extend(
            index_page.iterate_record_header(
                f,
                value_parser=default_value_parser,
                page=first_leaf_page_no,  # ctx
            )
        )
        first_leaf_page_no = index_page.fil.next_page

    if in_json:
        print(json.dumps([dataclasses.asdict(v) for v in values], default=str))
        return
    values = [f"({','.join(v)})" for v in values]

    table_name = f"`{table_object.schema_ref}`.`{table_object.name}`"
    if not oneline:
        print(
            f"INSERT INTO {table_name}({','.join(table_object.keys())}) values {', '.join(values)}"
        )
    else:
        for v in values:
            print(
                f"INSERT INTO {table_name}({','.join(table_object.keys())}) values {v};"
            )

    return


#
# 'type': sql/dd/types/column.h::enum_column_type
# column_key : ag --cpp \ CK_NONE

# column_type_utf8 -> ag --cpp '::sql_type'

not_focus_col_name = ["DB_TRX_ID", "DB_ROLL_PTR", "DB_ROW_ID"]
